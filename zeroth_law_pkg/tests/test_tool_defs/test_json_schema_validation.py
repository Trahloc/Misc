# FILE: tests/test_tool_defs/test_json_schema_validation.py
"""
Validates tool definition JSON files against the defined schema.
"""

import json
import pytest
import logging
from pathlib import Path
import sys
import jsonschema  # Import the library

# Reuse constants and helpers from TXT test
from tests.test_tool_defs.test_ensure_txt_baselines_exist import (
    MANAGED_COMMAND_SEQUENCES,
    command_sequence_to_id,
)

# Import fixtures from top-level conftest
from tests.conftest import ZLT_ROOT, TOOLS_DIR, ZLT_SCHEMA_PATH

# --- Add project root to path for sibling imports ---
# _test_file_path = Path(__file__).resolve()
# _project_root = _test_file_path.parents[2]
# _src_path = _project_root / "src"
# if str(_src_path) not in sys.path:
#     sys.path.insert(0, str(_src_path))

# Use utility function for sequence ID generation
from zeroth_law.lib.utils import command_sequence_to_id

# Import fixtures from this directory's conftest
# (WORKSPACE_ROOT, TOOLS_DIR, ZLT_SCHEMA_PATH, managed_sequences)
from .conftest import managed_sequences  # Import the fixture

# Assuming refactored schema validator component exists
from zeroth_law.dev_scripts.schema_validator import validate_tool_json_schema, SchemaValidationStatus

# Setup logger for this test module
log = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# Path to the schema file (relative to workspace root)
SCHEMA_PATH_RELATIVE = Path("src/zeroth_law/schemas/tool_definition_schema.json")


@pytest.fixture(scope="module")
def tool_definition_schema(WORKSPACE_ROOT):
    """Loads the tool definition JSON schema."""
    schema_path = WORKSPACE_ROOT / SCHEMA_PATH_RELATIVE
    if not schema_path.is_file():
        pytest.fail(f"Schema file not found at expected location: {schema_path}")
    try:
        with open(schema_path, "r", encoding="utf-8") as f:
            schema = json.load(f)
        # Basic check to ensure it looks like a schema
        assert "$schema" in schema
        assert "properties" in schema
        return schema
    except json.JSONDecodeError as e:
        pytest.fail(f"Failed to decode schema file {schema_path}: {e}")
    except Exception as e:
        pytest.fail(f"Failed to load schema file {schema_path}: {e}")


# --- Test Function (Uses managed_sequences fixture) ---


def test_all_json_schema_validation(
    managed_sequences: list,  # Use the fixture
    tool_definition_schema,  # Use the schema fixture
    WORKSPACE_ROOT: Path,  # Existing fixture
    TOOLS_DIR: Path,  # Existing fixture
):
    """Validates all managed tool JSON definitions against the schema."""

    if not managed_sequences:
        pytest.skip("No managed sequences generated by fixture.")

    failures = []
    validation_count = 0
    for command_parts in managed_sequences:
        if not command_parts:
            log.warning("Skipping empty command parts tuple in schema validation.")
            continue

        tool_id = command_sequence_to_id(command_parts)
        tool_name = command_parts[0]
        json_file = TOOLS_DIR / tool_name / f"{tool_id}.json"
        relative_json_path = json_file.relative_to(WORKSPACE_ROOT)

        # Skip validation if JSON file doesn't exist (consistency check handles this)
        if not json_file.is_file():
            log.debug(f"Skipping schema validation for {tool_id}: JSON file missing at {relative_json_path}")
            continue

        validation_count += 1
        # Use the refactored schema validator
        status, error_details = validate_tool_json_schema(json_file, tool_definition_schema)

        if status == SchemaValidationStatus.INVALID_JSON:
            failures.append(f"{tool_id} ({relative_json_path}): Invalid JSON - {error_details}")
        elif status == SchemaValidationStatus.SCHEMA_VIOLATION:
            # Format the jsonschema error details for readability
            error_str = "\n".join([f"  - {err.message} (Path: {list(err.path)})" for err in error_details])
            failures.append(f"{tool_id} ({relative_json_path}): Schema validation failed:\n{error_str}")
        elif status == SchemaValidationStatus.VALID:
            log.debug(f"Schema validation PASSED for {tool_id}.")
        # No need to check for FILE_NOT_FOUND again here

    log.info(f"Schema validation attempted for {validation_count} existing JSON files.")
    if failures:
        pytest.fail("\n\n".join(failures), pytrace=False)
    elif validation_count == 0:
        log.warning("No existing JSON files found to perform schema validation.")
    else:
        log.info(f"All {validation_count} checked JSON files passed schema validation.")
